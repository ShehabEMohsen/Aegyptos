{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "#Basma\n",
    "# classifer = joblib.load(\"C:/Users/basma/Fourth Year/Graduation_Project/squeezenetfinetuned.pkl\")\n",
    "\n",
    "#Bassem\n",
    "classifer = joblib.load(\"squeezenetuntrained.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SqueezeNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (3): Fire(\n",
       "      (squeeze): Conv2d(96, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Fire(\n",
       "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Fire(\n",
       "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (7): Fire(\n",
       "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Fire(\n",
       "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Fire(\n",
       "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Fire(\n",
       "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (12): Fire(\n",
       "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (squeeze_activation): ReLU(inplace=True)\n",
       "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (expand1x1_activation): ReLU(inplace=True)\n",
       "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (expand3x3_activation): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Conv2d(512, 1072, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loaded_model = pickle.load(\"squeezenetfinetuned.pkl\")\n",
    "import sklearn \n",
    "import numpy as np\n",
    "\n",
    "model = pickle.load(open('squeezenetuntrained.pkl', 'rb'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Segmentation then Cropping algorithm \n",
    "import cv2\n",
    "from imutils import contours\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "# Load image, grayscale, Otsu's threshold\n",
    "image_array = []\n",
    "results = []\n",
    "# image = cv2.imread('C:/Users/basma/Fourth Year/Graduation_Project/O001 (1).png')\n",
    "# image_array.append(image)\n",
    "# gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# thresh = cv2.threshold(gray,0,255,cv2.THRESH_OTSU + cv2.THRESH_BINARY)[1]\n",
    "# inv = cv2.bitwise_not(thresh)\n",
    "# rgb = cv2.cvtColor(inv, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "#---------------------------------------------------------------------\n",
    "def Otsu(myImage):\n",
    "  sample_image = cv2.imread(myImage)\n",
    "  img = cv2.cvtColor(sample_image,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "  # plt.axis('off')\n",
    "  # plt.imshow(img)\n",
    "\n",
    "  img_gray=cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "  thresh = threshold_otsu(img_gray)\n",
    "  img_otsu  = img_gray < thresh\n",
    "\n",
    "  # plt.imshow(img_otsu)\n",
    "\n",
    "  filtered = filter_image(img, img_otsu)\n",
    "  filteredBW=cv2.cvtColor(filtered,cv2.COLOR_RGB2GRAY)\n",
    "  return filteredBW\n",
    "\n",
    "\n",
    "\n",
    "def filter_image(image, mask):\n",
    "\n",
    "    r = image[:,:,0] * mask\n",
    "    g = image[:,:,1] * mask\n",
    "    b = image[:,:,2] * mask\n",
    "\n",
    "    return np.dstack([r,g,b])\n",
    "\n",
    "image = Otsu('C:/Users/basma/Fourth Year/Graduation_Project/D021.png')\n",
    "\n",
    "# gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# thresh = cv2.threshold(gray,0,255,cv2.THRESH_OTSU + cv2.THRESH_BINARY)[1]\n",
    "# inv = cv2.bitwise_not(thresh)\n",
    "\n",
    "cv2.imwrite('image2.png', image)\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "# Find contours, sort from left-to-right, then crop\n",
    "# cnts = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "# cnts, _ = contours.sort_contours(cnts, method=\"left-to-right\")\n",
    "\n",
    "# ROI_number = 0\n",
    "# for c in cnts:\n",
    "#     area = cv2.contourArea(c)\n",
    "#     if area > 50:\n",
    "#         x,y,w,h = cv2.boundingRect(c)\n",
    "#         ROI = 255 - image[y:y+h, x:x+w]\n",
    "#         img1 = cv2.copyMakeBorder(ROI, 20,20,20,20,cv2.BORDER_CONSTANT, value=[0,0,0])\n",
    "#         cv2.imwrite('ROIVVV_{}.png'.format(ROI_number), img1)\n",
    "        \n",
    "#         # image_array.append(img1)\n",
    "#         cv2.rectangle(image, (x, y), (x + w, y + h), (36,255,12), 2)\n",
    "#         ROI_number += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([19.2779,  3.9257,  7.1866,  ...,  1.0307,  0.5112,  0.8537])\n",
      "D021 0.9993090629577637\n",
      "S010 0.00026815372984856367\n",
      "S002 0.0001975266495719552\n",
      "D022 8.038392115850002e-05\n",
      "D048A 7.427437230944633e-05\n",
      "D021\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "import cv2\n",
    "\n",
    "#Basma\n",
    "input_image = Image.open('image2.png').convert('RGB')\n",
    "# input_image = Image.open('ROIVVV_0.png').convert('RGB')\n",
    "# input_image = Image.open('C:/Users/basma/Fourth Year/Graduation_Project/SegmentedDatasetAgain/train/A040/A040_1.png').convert('RGB')\n",
    "#Bassem\n",
    "# input_image = Image.open('D:/Ahmed Bassem/MIU/Year 4/Graduation Project/Datasets/SegmentedDataset/SegmentedDataset/test/O001/O001_1.png').convert('RGB')\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    # transforms.Pad(50),\n",
    "])\n",
    "input_tensor = preprocess(input_image)\n",
    "# input_tensor = preprocess(Image.fromarray(i))\n",
    "input_batch = input_tensor.unsqueeze(0)\n",
    "if torch.cuda.is_available():\n",
    "    input_batch = input_batch.to('cuda')\n",
    "    model.to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "\n",
    "# Tensor of shape 1000, with confidence scores over Aegyptos' 1072 classes\n",
    "print(output[0])\n",
    "# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "\n",
    "# Read the categories\n",
    "#Basma\n",
    "with open(\"classes_names.txt\", \"r\") as f:\n",
    "\n",
    "#Bassem\n",
    "# with open(\"D:/Ahmed Bassem/MIU\\Year 4/Graduation Project/classes_names.txt\", \"r\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]\n",
    "# Show top categories per image\n",
    "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "for i in range(top5_prob.size(0)):\n",
    "    print(categories[top5_catid[i]], top5_prob[i].item())\n",
    "\n",
    "top1 = categories[top5_catid[0]]\n",
    "print(top1)\n",
    "results.append(top1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\basma\\Fourth Year\\Graduation_Project\\Aegyptos backend\\Aegyptos\\predictions.ipynb Cell 5\u001b[0m in \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/basma/Fourth%20Year/Graduation_Project/Aegyptos%20backend/Aegyptos/predictions.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# im = Image.fromarray(image_array[0])\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/basma/Fourth%20Year/Graduation_Project/Aegyptos%20backend/Aegyptos/predictions.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# im.show()\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/basma/Fourth%20Year/Graduation_Project/Aegyptos%20backend/Aegyptos/predictions.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m,image_array[\u001b[39m1\u001b[39;49m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/basma/Fourth%20Year/Graduation_Project/Aegyptos%20backend/Aegyptos/predictions.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m cv2\u001b[39m.\u001b[39mwaitKey(\u001b[39m0\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/basma/Fourth%20Year/Graduation_Project/Aegyptos%20backend/Aegyptos/predictions.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m cv2\u001b[39m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# im = Image.fromarray(image_array[0])\n",
    "# im.show()\n",
    "cv2.imshow(\"test\",image_array[1])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A040 0.8683706521987915\n",
      "A040A 0.08197934925556183\n",
      "A049 0.03442122042179108\n",
      "C003 0.00968263577669859\n",
      "A041 0.0015775265637785196\n",
      "A040\n"
     ]
    }
   ],
   "source": [
    "# # Read the categories\n",
    "\n",
    "# #Basma\n",
    "# # with open(\"C:/Users/basma/Fourth Year/Graduation_Project/classes_names.txt\", \"r\") as f:\n",
    "\n",
    "# #Bassem\n",
    "# with open(\"D:/Ahmed Bassem/MIU\\Year 4/Graduation Project/classes_names.txt\", \"r\") as f:\n",
    "#     categories = [s.strip() for s in f.readlines()]\n",
    "# # Show top categories per image\n",
    "# top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "# for i in range(top5_prob.size(0)):\n",
    "#     print(categories[top5_catid[i]], top5_prob[i].item())\n",
    "\n",
    "# top1 = categories[top5_catid[0]]\n",
    "# print(top1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'AA029' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\basma\\Fourth Year\\Graduation_Project\\Aegyptos backend\\Aegyptos\\predictions.ipynb Cell 6\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/basma/Fourth%20Year/Graduation_Project/Aegyptos%20backend/Aegyptos/predictions.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatching_algorithm\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mma\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/basma/Fourth%20Year/Graduation_Project/Aegyptos%20backend/Aegyptos/predictions.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(ma\u001b[39m.\u001b[39;49mdictionary_matching(top1))\n",
      "File \u001b[1;32mc:\\Users\\basma\\Fourth Year\\Graduation_Project\\Aegyptos backend\\Aegyptos\\matching_algorithm.py:68\u001b[0m, in \u001b[0;36mdictionary_matching\u001b[1;34m(top1)\u001b[0m\n\u001b[0;32m     66\u001b[0m key_list\u001b[39m=\u001b[39m\u001b[39mlist\u001b[39m(str_list\u001b[39m.\u001b[39mkeys())\n\u001b[0;32m     67\u001b[0m val_list\u001b[39m=\u001b[39m\u001b[39mlist\u001b[39m(str_list\u001b[39m.\u001b[39mvalues())\n\u001b[1;32m---> 68\u001b[0m ind\u001b[39m=\u001b[39mval_list\u001b[39m.\u001b[39;49mindex(top1)\n\u001b[0;32m     69\u001b[0m key_list[ind]\n\u001b[0;32m     71\u001b[0m \u001b[39m# print(key_list[ind])\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: 'AA029' is not in list"
     ]
    }
   ],
   "source": [
    "import matching_algorithm as ma\n",
    "print(ma.dictionary_matching(top1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import googletrans\n",
    "from googletrans import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = ma.dictionary_matching(top1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "منزل\n"
     ]
    }
   ],
   "source": [
    "translator = googletrans.Translator()\n",
    "translate=translator.translate(match,dest='arabic')\n",
    "print(translate.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0976154a26863e578314ad5834e0d6ce38b742f452dd11bbe0b3fd5514356396"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
